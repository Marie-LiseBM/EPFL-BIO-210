{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b493c9e",
   "metadata": {},
   "source": [
    "### BIO-210: Projects in Informatics for SV\n",
    "# Python Introduction 3 - Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52851b64",
   "metadata": {},
   "source": [
    "Scikit-learn is a python library offering a set of tools for data mining, data analysis and machine learning (https://scikit-learn.org/stable/). Today you will learn how to load a dataset and how to perform some elementary exploration and visualization. You will then apply two important data analysis techniques: a clustering algorithm (k-means) and linear regression. Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.datasets as sk_data\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as cv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# We will use a custom library with visualizations developed for this exercise\n",
    "import lib.viz as viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b1a51",
   "metadata": {},
   "source": [
    "Today we will make plotting easy for you, as the lesson about visualization will come later in this course. For the moment, just call the function <code>viz.plot()</code> and give it the following arguments: x, y, color, plot_type ('line' or 'scatter'). Here follows a minimal example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "y = np.sqrt(x)\n",
    "viz.plot(x, y, 'green', 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253aabf2",
   "metadata": {},
   "source": [
    "<code>sklearn.datasets</code> is the scikit-learn module to handle sets of data. It includes some toy dataset to experiment with your algorithms, but it also allows you to load real-world datasets or to generate data with specific structures, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_data.make_blobs(n_samples=100, centers=3, n_features=2, center_box=(-30.0, 30.0), random_state=0)\n",
    "print(X.shape, y.shape, type(y))\n",
    "\n",
    "viz.plot(x = X[y==1,0], y = X[y==1,1], color='blue', plot_type='scatter')\n",
    "viz.plot(x = X[y==0,0], y = X[y==0,1], color='green', plot_type='scatter')\n",
    "viz.plot(x = X[y==2,0], y = X[y==2,1], color='red', plot_type='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df523e9a",
   "metadata": {},
   "source": [
    "## Clustering (k-means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebdd75",
   "metadata": {},
   "source": [
    "The k-means algorithm clusters data by trying to separate samples in k groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares. This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.\n",
    "\n",
    "You remember the bonus exercise from last week?\n",
    "Now we want to first implement k-means with numpy and then have a look on how to do it with scikit-learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20383d1c",
   "metadata": {},
   "source": [
    "**Exercise 1**. Implement k-means clustering to group features related to potential breast cancer masses. Clustering algorithms are used to group data that are similar to each other. In this case we would like to create 2 clusters. If the features are meaningful, each group should include a majority of positive (breast cancer) or negative (non breast cancer) outcomes. Proceed as follows:\n",
    "\n",
    "1 - Run the cell below, which downloads the dataset and saves the breast cancer features and target labels (cancer / non-cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617707ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "features = data.data\n",
    "target = data.target\n",
    "print(\"Shape of the feature matrix: \", features.shape)\n",
    "print(\"Shape of the label vector: \", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4406e9ac",
   "metadata": {},
   "source": [
    "2 - Normalize the features by subtracting the mean from each column and dividing it by its standard deviation. Normalizing the features is a standard way to make the clustering robust to the scale of the features. You can use the relevant <code>numpy</code> functions to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de07d3a",
   "metadata": {},
   "source": [
    "3 - Each cluster is characterized by a centroid, which is its center of mass. The k-means algorithm will start from two random centroids and iteratively update their values. Define the initial values of the centroids by creating 2 vectors of size equal to the number of features, containing random values sampled from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb67340",
   "metadata": {},
   "source": [
    "Now define the iteration loop, which should run until the centroids do not change their value for two consecutive iterations (or the cluster assignment does not change for two consecutive iterations). In each step:\n",
    "\n",
    "4 - Assign each element of the dataset to the closest centroid. Measure the distance between each centroid and an element with the standard euclidean distance. If the element is closer to the centroid 0, then it belongs to the cluster 0. Otherwise it belongs to the cluster 1. Run this assignment for all the elements.\n",
    "\n",
    "5 - Update the centroids. They are the average of all the elements assigned to their cluster. Hint: if <code>features</code> is your features matrix and <code>clusters</code> the vector of the cluster assignment, you can get the features of the elements in a certain cluster with the code <code>features[clusters == cluster_id]</code>\n",
    "\n",
    "Verify that the algorithm converges in a finite number of steps. Once the clustering is completed, check the distribution of target labels associated to the elements of each cluster (Hint: for both clusters, count the elements with label 0 or 1).  If the distribution is substantially different between the two clusters, it means that this simple algorithm has learnt how to approximately distinguish a cancer mass from a non-cancer one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b1d20",
   "metadata": {},
   "source": [
    "### Now we want to have a look on how to run k-means with scikit-learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4e64f",
   "metadata": {},
   "source": [
    "Clustering of unlabeled data can be performed with the module <code>sklearn.cluster</code>.\n",
    "\n",
    "One important thing to note is that the clustering algorithms can take different kinds of matrix as input. All the methods accept standard data matrices of shape <code>(n_samples, n_features)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f868332",
   "metadata": {},
   "source": [
    "First we import the KMeans algorithm and a scaler object that helps us normalizing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47629947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f9fad1",
   "metadata": {},
   "source": [
    "We can use the **StandardScaler** to normalize our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62436f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "norm_features = sc.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b30e3",
   "metadata": {},
   "source": [
    "There are 3 functions in all the clustering classes:\n",
    "- **fit()** is building the model from the training data (e.g. finding the centroids)\n",
    "- **predict()** is assigning labels to test data after building the model\n",
    "- **fit_predict()** is doing both in the same data (e.g in kmeans, it finds the centroids and assigns the labels to the dataset)\n",
    "\n",
    "We are finally ready to run k-means clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=2, n_init=10)\n",
    "kmeans.fit_predict(norm_features)\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21bfa2",
   "metadata": {},
   "source": [
    "A simple way to check whether the distribution of the two classes (cancer or no-cancer) in each cluster is different is to print the confusion matrix. The confusion matrix for an N classes problem (in our case N=2) is an N x N matrix in which each column represents a cluster and each row a label. If the numbers on one of the diagonal are considerably larger than on the other one, this means that there is a label distribution inbalance between the clusters and therefore the algorithm worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bd1fd",
   "metadata": {},
   "source": [
    "For an overview of the other metrics functions available in scikit-learn, take a look at sklearn-metrics here: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea067c53",
   "metadata": {},
   "source": [
    "**Exercise 2**. Compare the performance of the scikit-learn implementation of k-means with the one of your own implementation. Measure the accuracy of each algorithm to check which implementation did a better job! Hint: to compute the accuracy, consider the cluster assignment as a label. If in cluster 0 there are more elements belonging to the \"cancer\" group, define \"0\" as the label \"cancer\" and \"1\" as the label \"non-cancer\", otherwise do the opposite. The label assignment can be different for the two clustering algorithms, because they do not now anything about the meaning of the label. Once you have assigned a prediction to each data point, compute the accuracy with <code>metrics.accuracy_score</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68536d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cfc7e4",
   "metadata": {},
   "source": [
    "**Exercise 3.** Usually the performances of the scikit-learn implementation of k-means performs differently from your own implementation. Can you give an explanation of this fact in your own words? (hint: look up the meaning of the parameters <code>init=k-means++</code> and <code>n_init</code>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56231f5",
   "metadata": {},
   "source": [
    " *Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e0666",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b53ec",
   "metadata": {},
   "source": [
    "In your linear algebra class you have studied methods to solve linear systems, even when they are overdetermined. To do that, the standard way to find a solution is to solve the system with the least squares method. Least squares is the basis of an important statistical tool: the linear regression. In fact, datasets often define an overdetermined system, as there are many more data points than features. Of course, scikit-learn offers its own implementation of it. Consider the following linear system\n",
    "\n",
    "\n",
    "$$Y = \\alpha +\\beta X +\\epsilon$$\n",
    "\n",
    "We **know**: the dataset $X$ (in the form of a matrix) and the target vector $Y$\n",
    "\n",
    "We **do not know**: the coefficient vectors $\\alpha$ and $\\beta$ and the residual noise vecotor $\\epsilon$\n",
    "\n",
    "**Goal:** Given $X$ and $Y$ produce estimates of $\\alpha$ and $\\beta$ denoted by $\\widehat{\\alpha}$ and $\\widehat{\\beta}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c691d",
   "metadata": {},
   "source": [
    "Input data comes in the form of pairs $\\left(X_i,Y_i\\right)$  for $i=1,\\ldots ,n$\n",
    "\n",
    "The **true regression line**: For **every** individual it should hold that:\n",
    "$$Y_i = \\alpha +\\beta X_i +\\epsilon_i$$\n",
    "\n",
    "\n",
    "**Error** for the $i$-th data point is: $$ \\epsilon_i = Y_i-\\alpha-\\beta X_i $$\n",
    "\n",
    "\n",
    "The **estimated regression line** : $$\\widehat{Y_i}=\\widehat{\\alpha}+\\widehat{\\beta}X_i$$\n",
    "\n",
    "\n",
    "**Residuals** measure the distance between each observation from the estimated regression line and are defined as follows: $$\\widehat{\\epsilon_i} = Y_i-\\widehat{Y_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbce249",
   "metadata": {},
   "source": [
    "##### Ordinary Least Squares Regression as an optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db610ca0",
   "metadata": {},
   "source": [
    "**Question**: How do we find $\\widehat{\\alpha}$ and $\\widehat{\\beta}$?\n",
    "\n",
    "**Answer**: By minimizing the residuals, or *sum of squared residuals* :\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{SSR} & = & \\sum_{i=1}^n \\widehat{\\epsilon_i}^2 \\\\\n",
    "& = & \\sum_{i=1}^n \\left(Y_i-\\widehat{Y_i}\\right)^2\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef328530",
   "metadata": {},
   "source": [
    "### Example I:\n",
    "Generate a dataset using the <code>datasets.makeregression()</code> function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_data.make_regression(n_samples=100, n_features=1, bias=0.1, noise=42, random_state=1)\n",
    "print(X.shape, y.shape)\n",
    "viz.plot(X, y, 'blue', 'scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd148c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "regr.fit(X, y)\n",
    "y_pred = regr.predict(X)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_, regr.intercept_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % metrics.mean_squared_error(y, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "viz.plot(X, y, 'blue', 'scatter')\n",
    "viz.plot(X, y_pred, 'red', 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771a3ca",
   "metadata": {},
   "source": [
    "### Now it's your turn!\n",
    "\n",
    "**Exercise 3**: Analyze the **multi-dimensional** california housing data with a linear regression model.\n",
    "\n",
    "First of all, load the housing data, which is already available in scikit-learn. It also comes with a lengthy description!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e522917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading housing data\n",
    "california = sk_data.fetch_california_housing()\n",
    "X = california[\"data\"]\n",
    "y = california[\"target\"]\n",
    "\n",
    "print(california['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645b1e6",
   "metadata": {},
   "source": [
    "First step: split the data into training and testing. Hint: use the function <code>cv.train_test_split()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c41825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a2db7",
   "metadata": {},
   "source": [
    "Now fit a linear regression model on the train data and evaluate it by computing the MSE for both the train and the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8df1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa81853",
   "metadata": {},
   "source": [
    "Print the coefficients for all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003edea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f54528",
   "metadata": {},
   "source": [
    "Plot the feature *MedInc* and the corresponding regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5747fec",
   "metadata": {},
   "source": [
    "Look at some example predictions on the test set and compare to the ground-truth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70caee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
